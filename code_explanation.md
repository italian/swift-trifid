# üéì –°–µ–º–∏–Ω–∞—Ä: –°–æ–∑–¥–∞–µ–º –ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç –¥–ª—è –ó–º–µ–π–∫–∏

–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –°–µ–≥–æ–¥–Ω—è –º—ã —Ä–∞–∑–±–µ—Ä–µ–º, –∫–∞–∫ –Ω–∞—É—á–∏—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä –∏–≥—Ä–∞—Ç—å –≤ "–ó–º–µ–π–∫—É" —Å –Ω—É–ª—è. –ú—ã –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—Å–∞–ª–∏ —Å–∫—Ä–∏–ø—Ç, –º—ã —Å–æ–∑–¥–∞–ª–∏ —Å–∏—Å—Ç–µ–º—É **Deep Reinforcement Learning (–ì–ª—É–±–æ–∫–æ–≥–æ –û–±—É—á–µ–Ω–∏—è —Å –ü–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º)**.

–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –≤—ã –¥—Ä–µ—Å—Å–∏—Ä—É–µ—Ç–µ —â–µ–Ω–∫–∞. –í—ã –Ω–µ –≥–æ–≤–æ—Ä–∏—Ç–µ –µ–º—É "–ø–æ–¥–Ω–∏–º–∏ –ª–∞–ø—É –Ω–∞ 10 —Å–º –∏ —Å–æ–≥–Ω–∏ —Å—É—Å—Ç–∞–≤". –í—ã –≥–æ–≤–æ—Ä–∏—Ç–µ "–õ–∞–ø—É!" –∏ –¥–∞–µ—Ç–µ –≤–∫—É—Å–Ω—è—à–∫—É, –µ—Å–ª–∏ –æ–Ω —Å–¥–µ–ª–∞–ª –ø—Ä–∞–≤–∏–ª—å–Ω–æ. –ï—Å–ª–∏ –æ–Ω –∫—É—Å–∞–µ—Ç –¥–∏–≤–∞–Ω ‚Äî –≤—ã –µ–≥–æ —Ä—É–≥–∞–µ—Ç–µ.
*   **–ê–≥–µ–Ω—Ç** ‚Äî —ç—Ç–æ –Ω–∞—à —â–µ–Ω–æ–∫ (–ó–º–µ–π–∫–∞).
*   **–°—Ä–µ–¥–∞** ‚Äî —ç—Ç–æ –∫–æ–º–Ω–∞—Ç–∞ (–ò–≥—Ä–æ–≤–æ–µ –ø–æ–ª–µ).
*   **–ù–∞–≥—Ä–∞–¥–∞** ‚Äî –≤–∫—É—Å–Ω—è—à–∫–∞ (+10) –∏–ª–∏ –Ω–∞–∫–∞–∑–∞–Ω–∏–µ (-10).

---

## üó∫Ô∏è –ö–∞—Ä—Ç–∞ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

–ù–∞—à–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Ç—Ä–µ—Ö –≥–ª–∞–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤. –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –æ–Ω–∏ —Å–≤—è–∑–∞–Ω—ã:

```mermaid
flowchart TD
    subgraph Game["Game Environment - game.py"]
        A[SnakeGameAI]
    end
    
    subgraph Agent["Agent - agent.py"]
        B[Agent Class]
    end
    
    subgraph Model["Neural Network - model.py"]
        C[LinearQNet]
        D[QTrainer]
    end
    
    A -->|State + Reward| B
    B -->|Action| A
    B -->|Training Data| C
    C -->|Prediction| B
    D -->|Update Weights| C
```

---

## 1. üéÆ –°—Ä–µ–¥–∞ (`game.py`)

–≠—Ç–æ "—Ñ–∏–∑–∏—á–µ—Å–∫–∏–π –º–∏—Ä" –Ω–∞—à–µ–π –∏–≥—Ä—ã. –ù–µ–π—Ä–æ—Å–µ—Ç—å –Ω–µ –≤–∏–¥–∏—Ç —ç–∫—Ä–∞–Ω, –∫–∞–∫ –º—ã. –ï–π –Ω—É–∂–Ω—ã —Ü–∏—Ñ—Ä—ã.

### –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: `play_step(action)`
–í –æ–±—ã—á–Ω–æ–π –∏–≥—Ä–µ –º—ã –∂–¥–µ–º –Ω–∞–∂–∞—Ç–∏—è –∫–ª–∞–≤–∏—à. –ó–¥–µ—Å—å –º—ã –∂–¥–µ–º –∫–æ–º–∞–Ω–¥—É –æ—Ç –ê–≥–µ–Ω—Ç–∞.

```python
def play_step(self, action):
    # 1. –î–≤–∏–≥–∞–µ–º—Å—è
    self._move(action) 
    
    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∂–∏–≤—ã –ª–∏ –º—ã
    if self.is_collision():
        return -10, True, score  # –ù–∞–∫–∞–∑–∞–Ω–∏–µ! –ò–≥—Ä–∞ –æ–∫–æ–Ω—á–µ–Ω–∞.
        
    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–µ–ª–∏ –ª–∏ –º—ã
    if self.head == self.food:
        return 10, False, score  # –í–∫—É—Å–Ω—è—à–∫–∞!
        
    # 4. –ü—Ä–æ—Å—Ç–æ –∏–¥–µ–º –¥–∞–ª—å—à–µ
    return 0, False, score       # –ù–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ.
```

**–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ?**
–≠—Ç–æ **–§—É–Ω–∫—Ü–∏—è –ù–∞–≥—Ä–∞–¥—ã (Reward Function)**. –≠—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± –æ–±—ä—è—Å–Ω–∏—Ç—å –ê–≥–µ–Ω—Ç—É, —á—Ç–æ —Ö–æ—Ä–æ—à–æ, –∞ —á—Ç–æ –ø–ª–æ—Ö–æ. –ï—Å–ª–∏ –º—ã —É–±–µ—Ä–µ–º –Ω–∞–∫–∞–∑–∞–Ω–∏–µ –∑–∞ —Å–º–µ—Ä—Ç—å, –∑–º–µ–π–∫–∞ –±—É–¥–µ—Ç –ø—Ä–æ—Å—Ç–æ –∫—Ä—É—Ç–∏—Ç—å—Å—è –Ω–∞ –º–µ—Å—Ç–µ.

---

## 2. üß† –ú–æ–∑–≥ (`model.py`)

–ó–¥–µ—Å—å –∂–∏–≤–µ—Ç –ù–µ–π—Ä–æ—Å–µ—Ç—å. –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º **DQN (Deep Q-Network)**.

### –ß—Ç–æ —Ç–∞–∫–æ–µ Q-Value?
`Q` –æ–∑–Ω–∞—á–∞–µ—Ç **Quality** (–ö–∞—á–µ—Å—Ç–≤–æ).
–î–ª—è –ª—é–±–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ (State) —Å–µ—Ç—å –ø—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å **–ö–∞—á–µ—Å—Ç–≤–æ** –∫–∞–∂–¥–æ–≥–æ –∏–∑ 3 –≤–æ–∑–º–æ–∂–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π:
1.  –ò–¥—Ç–∏ –ø—Ä—è–º–æ
2.  –ü–æ–≤–µ—Ä–Ω—É—Ç—å –Ω–∞–ø—Ä–∞–≤–æ
3.  –ü–æ–≤–µ—Ä–Ω—É—Ç—å –Ω–∞–ª–µ–≤–æ

–ü—Ä–∏–º–µ—Ä:
*   –°–∏—Ç—É–∞—Ü–∏—è: –í–ø–µ—Ä–µ–¥–∏ —Å—Ç–µ–Ω–∞, —Å–ª–µ–≤–∞ –µ–¥–∞.
*   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–µ—Ç–∏: `[Straight: -10, Right: 0, Left: 10]`
*   –ê–≥–µ–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç **Left**, –ø–æ—Ç–æ–º—É —á—Ç–æ 10 ‚Äî —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ —á–∏—Å–ª–æ.

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –°–µ—Ç–∏ (`LinearQNet`)
–≠—Ç–æ –ø—Ä–æ—Å—Ç–∞—è —Å–µ—Ç—å "Feed Forward" (–ø—Ä—è–º–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è).

```mermaid
flowchart LR
    A[Input Layer<br/>11 neurons] --> B[Hidden Layer<br/>256 neurons]
    B --> C[Output Layer<br/>3 neurons]
```

*   **–í—Ö–æ–¥ (11)**: –ì–ª–∞–∑–∞ –∑–º–µ–π–∫–∏ (–≥–¥–µ –µ–¥–∞? –≥–¥–µ —Å—Ç–µ–Ω—ã?).
*   **–°–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π (256)**: –ó–¥–µ—Å—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç "–º—ã—à–ª–µ–Ω–∏–µ". –ù–µ–π—Ä–æ–Ω—ã –Ω–∞—Ö–æ–¥—è—Ç –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏.
*   **–í—ã—Ö–æ–¥ (3)**: –û—Ü–µ–Ω–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π `[–ü—Ä—è–º–æ, –í–ø—Ä–∞–≤–æ, –í–ª–µ–≤–æ]`.

### –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –û–±—É—á–µ–Ω–∏—è (`QTrainer`)
–ö–∞–∫ —Å–µ—Ç—å —É—á–∏—Ç—Å—è? –ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º **–£—Ä–∞–≤–Ω–µ–Ω–∏–µ –ë–µ–ª–ª–º–∞–Ω–∞**:

$$ Q_{new} = Reward + \gamma \cdot \max(Q_{next}) $$

–ü–æ-—Ä—É—Å—Å–∫–∏:
> "–¶–µ–Ω–Ω–æ—Å—Ç—å —Ç–µ–∫—É—â–µ–≥–æ —à–∞–≥–∞ = –ú–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞ + (–°–∫–∏–¥–∫–∞ * –õ—É—á—à–µ–µ, —á—Ç–æ –º–æ–∂–µ—Ç —Å–ª—É—á–∏—Ç—å—Å—è –¥–∞–ª—å—à–µ)"

–ï—Å–ª–∏ –∑–º–µ–π–∫–∞ —Å–¥–µ–ª–∞–ª–∞ —à–∞–≥ –∏ —É–≤–∏–¥–µ–ª–∞ –µ–¥—É, —ç—Ç–æ—Ç —à–∞–≥ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Ü–µ–Ω–Ω—ã–º, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω –≤–µ–¥–µ—Ç –∫ –Ω–∞–≥—Ä–∞–¥–µ –≤ –±—É–¥—É—â–µ–º.

---

## 3. üïµÔ∏è –ê–≥–µ–Ω—Ç (`agent.py`)

–≠—Ç–æ "–¥–∏—Ä–∏–∂–µ—Ä", –∫–æ—Ç–æ—Ä—ã–π —Å–æ–µ–¥–∏–Ω—è–µ—Ç –ò–≥—Ä—É –∏ –ú–æ–∑–≥.

### –ó—Ä–µ–Ω–∏–µ –ê–≥–µ–Ω—Ç–∞ (`get_state`)
–ê–≥–µ–Ω—Ç –Ω–µ –≤–∏–¥–∏—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É. –û–Ω –≤–∏–¥–∏—Ç –≤–µ–∫—Ç–æ—Ä –∏–∑ 11 —á–∏—Å–µ–ª (0 –∏–ª–∏ 1):

1.  **–û–ø–∞—Å–Ω–æ—Å—Ç—å (3)**: –ï—Å—Ç—å –ª–∏ —Å—Ç–µ–Ω–∞ –ü—Ä—è–º–æ? –°–ø—Ä–∞–≤–∞? –°–ª–µ–≤–∞?
2.  **–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (4)**: –ö—É–¥–∞ –º—ã —Å–µ–π—á–∞—Å –ø–æ–ª–∑–µ–º? (–í–≤–µ—Ä—Ö, –í–Ω–∏–∑, –í–ª–µ–≤–æ, –í–ø—Ä–∞–≤–æ)
3.  **–ï–¥–∞ (4)**: –ì–¥–µ –µ–¥–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≥–æ–ª–æ–≤—ã? (–ï–¥–∞ —Å–ª–µ–≤–∞? –ï–¥–∞ —Å–ø—Ä–∞–≤–∞? –∏ —Ç.–¥.)

–ü—Ä–∏–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞: `[1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]`
*   `1` (–û–ø–∞—Å–Ω–æ—Å—Ç—å –ø—Ä—è–º–æ)
*   `0, 1, 0, 0` (–î–≤–∏–∂–µ–º—Å—è –≤–ø—Ä–∞–≤–æ)
*   `0, 0, 1, 0` (–ï–¥–∞ —Å–≤–µ—Ä—Ö—É)
*   **–í—ã–≤–æ–¥:** "–Ø –ø–æ–ª–∑—É –≤–ø—Ä–∞–≤–æ, –≤–ø–µ—Ä–µ–¥–∏ —Å—Ç–µ–Ω–∞, –µ–¥–∞ —Å–≤–µ—Ä—Ö—É. –ù–∞–¥–æ –ø–æ–≤–µ—Ä–Ω—É—Ç—å –Ω–∞–ª–µ–≤–æ!"

### –ü–∞–º—è—Ç—å (`deque`)
–ê–≥–µ–Ω—Ç –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –≤—Å–µ —Å–≤–æ–∏ —à–∞–≥–∏ –≤ `memory`.
–ó–∞—á–µ–º? –ß—Ç–æ–±—ã —É—á–∏—Ç—å—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–æ–º, —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å —Å–µ–∫—É–Ω–¥—É –Ω–∞–∑–∞–¥, –Ω–æ –∏ –ø–µ—Ä–µ–æ—Å–º—ã—Å–ª–∏–≤–∞—Ç—å –ø—Ä–æ—à–ª—ã–π –æ–ø—ã—Ç.
–≠—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è **Experience Replay (–ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏–µ –æ–ø—ã—Ç–∞)**.
–ü–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —Å–º–µ—Ä—Ç–∏ –ê–≥–µ–Ω—Ç –±–µ—Ä–µ—Ç 1000 —Å–ª—É—á–∞–π–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ –∏ —Ç—Ä–µ–Ω–∏—Ä—É–µ—Ç –Ω–∞ –Ω–∏—Ö –º–æ–∑–≥ –∑–∞–Ω–æ–≤–æ. –≠—Ç–æ –¥–µ–ª–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–º.

### Exploration vs Exploitation (–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–ª–∏ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ)
–í –Ω–∞—á–∞–ª–µ –æ–±—É—á–µ–Ω–∏—è –∑–º–µ–π–∫–∞ —Ç—É–ø–∞—è. –ï—Å–ª–∏ –æ–Ω–∞ –±—É–¥–µ—Ç —Å–ª—É—à–∞—Ç—å —Å–≤–æ–π –Ω–µ–æ–±—É—á–µ–Ω–Ω—ã–π –º–æ–∑–≥, –æ–Ω–∞ –±—É–¥–µ—Ç –¥–µ–ª–∞—Ç—å –≥–ª—É–ø–æ—Å—Ç–∏.
–ü–æ—ç—Ç–æ–º—É –º—ã –≤–≤–æ–¥–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä `epsilon` (—Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å).
*   –í –Ω–∞—á–∞–ª–µ `epsilon` –≤—ã—Å–æ–∫–∏–π: –ó–º–µ–π–∫–∞ —Ö–æ–¥–∏—Ç —Å–ª—É—á–∞–π–Ω–æ (–∏—Å—Å–ª–µ–¥—É–µ—Ç –º–∏—Ä).
*   –°–æ –≤—Ä–µ–º–µ–Ω–µ–º `epsilon` –ø–∞–¥–∞–µ—Ç: –ó–º–µ–π–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç –¥–æ–≤–µ—Ä—è—Ç—å —Å–≤–æ–µ–º—É –æ–ø—ã—Ç—É (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∑–Ω–∞–Ω–∏—è).

```python
# agent.py
if random.randint(0, 200) < self.epsilon:
    move = random_move() # –†–∏—Å–∫—É–µ–º –∏ –ø—Ä–æ–±—É–µ–º –Ω–æ–≤–æ–µ!
else:
    move = model_prediction() # –î–µ–ª–∞–µ–º –∫–∞–∫ —É—á–∏–ª–∏.
```

---

## –ò—Ç–æ–≥: –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–º–µ—Å—Ç–µ?

1.  **–ù–∞–±–ª—é–¥–µ–Ω–∏–µ**: –ê–≥–µ–Ω—Ç —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ –º–∏—Ä (`get_state`).
2.  **–†–µ—à–µ–Ω–∏–µ**: –ê–≥–µ–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ (`get_action`).
3.  **–î–µ–π—Å—Ç–≤–∏–µ**: –ò–≥—Ä–∞ –¥–≤–∏–≥–∞–µ—Ç –∑–º–µ–π–∫—É (`play_step`).
4.  **–†–µ–∑—É–ª—å—Ç–∞—Ç**: –ò–≥—Ä–∞ –≥–æ–≤–æ—Ä–∏—Ç "–¢—ã –∂–∏–≤" –∏–ª–∏ "–¢—ã —É–º–µ—Ä" (`reward`).
5.  **–û–±—É—á–µ–Ω–∏–µ**:
    *   **Short Memory**: –ê–≥–µ–Ω—Ç —Å—Ä–∞–∑—É –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –≤–µ—Å–∞ —Å–µ—Ç–∏ (–Ω–µ–º–Ω–æ–≥–æ).
    *   **Long Memory**: –ï—Å–ª–∏ –∏–≥—Ä–∞ –∫–æ–Ω—á–∏–ª–∞—Å—å, –ê–≥–µ–Ω—Ç —Å–∞–¥–∏—Ç—Å—è –∏ "–æ–±–¥—É–º—ã–≤–∞–µ—Ç" 1000 –ø—Ä–æ—à–ª—ã—Ö —à–∞–≥–æ–≤.

–í–æ—Ç —Ç–∞–∫, —à–∞–≥ –∑–∞ —à–∞–≥–æ–º, —á–µ—Ä–µ–∑ —Ç—ã—Å—è—á–∏ –æ—à–∏–±–æ–∫, –Ω–∞—à–∞ –ó–º–µ–π–∫–∞ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –≥—Ä–æ—Å—Å–º–µ–π—Å—Ç–µ—Ä–æ–º! üêçüèÜ
